{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import seaborn as sns; sns.set(style='ticks', color_codes=True)\n",
    "\n",
    "from pandas.plotting import parallel_coordinates\n",
    "from sklearn import preprocessing\n",
    "from operator import itemgetter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distance calculation\n",
    "\n",
    "def bhattacharyyan_distance(v1, v2):\n",
    "    if len(v1) != len(v2):\n",
    "        return -1\n",
    "    \n",
    "    return sum([math.sqrt(v1[i] * v2[i]) for i in range(0, len(v1))])\n",
    "\n",
    "def euclidean_distance(v1,v2):\n",
    "    if len(v1) != len(v2):\n",
    "        return -1\n",
    "    \n",
    "    return math.sqrt(sum((v1[i]-v2[i])**2 for i in range(0, len(v1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization\n",
    "\n",
    "def normalize_max_unknown(base_df):\n",
    "    df = base_df.copy()\n",
    "    \n",
    "    col_size = len(df.columns)\n",
    "    for i in range(1, col_size):\n",
    "        vector = df.iloc[:,i]\n",
    "        min = np.min(vector)\n",
    "        max = np.max(vector)\n",
    "        \n",
    "        df.iloc[:,i] = [(x - float(min)) / (float(max) - float(min)) for x in vector]\n",
    "        \n",
    "    return df\n",
    "\n",
    "def normalize_time_series(base_df):\n",
    "    df = base_df.copy()\n",
    "    mean_list = list()\n",
    "    stdev_list = list()\n",
    "    \n",
    "    for i in range(1, len(df)):\n",
    "        vector = df.iloc[i].values\n",
    "        \n",
    "        mean = np.mean(vector)\n",
    "        stdev = np.std(vector, ddof=1)\n",
    "        mean_list.append(mean)\n",
    "        stdev_list.append(stdev)\n",
    "        \n",
    "        df.iloc[i] = [(x - mean) / stdev for x in vector]\n",
    "        \n",
    "    return df\n",
    "#     return df, mean_list, stdev_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Visualization\n",
    "\n",
    "def parallel_lines(df, target_category):\n",
    "    plt.pyplot.figure(figsize=(30,10))\n",
    "\n",
    "    parallel_plt = parallel_coordinates(df, target_category)\n",
    "    plt.pyplot.savefig('%s_parallel.png' % target_category)\n",
    "    \n",
    "def scatter_plot(df, target_category):\n",
    "    scatter_plt = sns.pairplot(df, hue=target_category)\n",
    "    scatter_plt.savefig('%s_scatter.png' % target_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Naive Bayes\n",
    "\n",
    "class NaiveBayes(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.label_ratio = list()\n",
    "        self.mean_variance_dict = {}\n",
    "    \n",
    "    def train(self, data, label, label_name):\n",
    "        #Compute for classification ratio - P(A) = P(0), P(A) = P(1)\n",
    "#         self.label_ratio.append(label.count(0) / len(label))\n",
    "#         self.label_ratio.append(label.count(1) / len(label))\n",
    "        \n",
    "        unique, counts = np.unique(label, return_counts=True)\n",
    "        label_count_dict = dict(zip(unique, counts))\n",
    "        self.label_ratio.append(label_count_dict[0])\n",
    "        self.label_ratio.append(label_count_dict[1])\n",
    "\n",
    "        zero_data = data.loc[data[label_name] == 0]\n",
    "        one_data = data.loc[data[label_name] == 1]\n",
    "        \n",
    "        for column in zero_data:\n",
    "            mean = np.mean(zero_data[column])\n",
    "            variance = np.var(zero_data[column])\n",
    "            self.mean_variance_dict[0] = {'mean':{column:mean}}\n",
    "            self.mean_variance_dict[0] = {'variance':{column:variance}}\n",
    "\n",
    "            \n",
    "        for column in one_data:\n",
    "            mean = np.mean(one_data[column])\n",
    "            variance = np.var(one_data[column])\n",
    "            self.mean_variance_dict[1] = {'mean':{column:mean}}\n",
    "            self.mean_variance_dict[1] = {'variance':{column:variance}}\n",
    "        \n",
    "df = pd.read_csv('sample_data.csv')\n",
    "clf = NaiveBayes().train(df, df['y'].values, 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45128684260947494"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = df.loc[0]\n",
    "v2 = df.loc[1]\n",
    "\n",
    "euclidean_distance(v1,v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
